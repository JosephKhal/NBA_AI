{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1890387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Change directory to root\n",
    "os.chdir('..')\n",
    "# Add the parent directory of src to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a558b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss, mean_absolute_error\n",
    "from src.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_palette = sns.color_palette(\"deep\")\n",
    "deep_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DB_PATH = config[\"database\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6235931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_predictor_data(seasons, predictors):\n",
    "    \"\"\"\n",
    "    Fetches data from the database for the specified seasons and predictors.\n",
    "    Args:\n",
    "        seasons (list): List of seasons (e.g., ['2023-2024']).\n",
    "        predictors (list): List of predictors (e.g., ['Baseline', 'Random']).\n",
    "    Returns:\n",
    "        DataFrame: Data containing game_id, predictor, prediction_set, home_score, away_score.\n",
    "    \"\"\"\n",
    "    # Using a context manager for the database connection\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        # Define the SQL query\n",
    "        query = f\"\"\"\n",
    "        SELECT p.game_id, p.predictor, p.prediction_set, gs.home_score, gs.away_score\n",
    "        FROM Predictions p\n",
    "        JOIN Games g ON p.game_id = g.game_id\n",
    "        JOIN GameStates gs ON p.game_id = gs.game_id AND gs.is_final_state = True\n",
    "        WHERE g.season IN ({','.join('?' for _ in seasons)})\n",
    "          AND p.predictor IN ({','.join('?' for _ in predictors)});\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query and load the data into a DataFrame\n",
    "        df = pd.read_sql_query(query, conn, params=seasons + predictors)\n",
    "\n",
    "    # Expand the JSON column 'prediction_set'\n",
    "    df[\"prediction_set\"] = df[\"prediction_set\"].apply(json.loads)\n",
    "    expanded_df = df.join(pd.json_normalize(df[\"prediction_set\"]))\n",
    "\n",
    "    # Drop the original 'prediction_set' column if no longer needed\n",
    "    expanded_df = expanded_df.drop(columns=[\"prediction_set\"])\n",
    "\n",
    "    # Calculate actual_home_margin\n",
    "    expanded_df[\"actual_home_margin\"] = (\n",
    "        expanded_df[\"home_score\"] - expanded_df[\"away_score\"]\n",
    "    )\n",
    "\n",
    "    # Assuming the JSON structure has keys like 'predicted_home_score' and 'predicted_away_score'\n",
    "    expanded_df[\"pred_home_margin\"] = (\n",
    "        expanded_df[\"predicted_home_score\"] - expanded_df[\"predicted_away_score\"]\n",
    "    )\n",
    "    expanded_df[\"pred_home_win_pct\"] = expanded_df[\"predicted_home_win_pct\"]\n",
    "\n",
    "    # Calculate actual_home_win_pct\n",
    "    expanded_df[\"actual_home_win_pct\"] = expanded_df.apply(\n",
    "        lambda row: (\n",
    "            1\n",
    "            if row[\"home_score\"] > row[\"away_score\"]\n",
    "            else (0 if row[\"home_score\"] < row[\"away_score\"] else 0.5)\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c941c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data):\n",
    "    \"\"\"\n",
    "    Calculate Log Loss and MAE metrics for the given data.\n",
    "    Args:\n",
    "        data (DataFrame): Data containing actual and predicted values.\n",
    "    Returns:\n",
    "        dict: Dictionary of metrics for each predictor.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for predictor in data[\"predictor\"].unique():\n",
    "        df_pred = data[data[\"predictor\"] == predictor]\n",
    "\n",
    "        # Log Loss for home_win_pct\n",
    "        log_loss_home_win_pct = log_loss(\n",
    "            df_pred[\"actual_home_win_pct\"], df_pred[\"pred_home_win_pct\"]\n",
    "        )\n",
    "\n",
    "        # MAE for home_score, away_score, and margin\n",
    "        mae_home_score = mean_absolute_error(\n",
    "            df_pred[\"home_score\"], df_pred[\"predicted_home_score\"]\n",
    "        )\n",
    "        mae_away_score = mean_absolute_error(\n",
    "            df_pred[\"away_score\"], df_pred[\"predicted_away_score\"]\n",
    "        )\n",
    "        mae_home_margin = mean_absolute_error(\n",
    "            df_pred[\"actual_home_margin\"], df_pred[\"pred_home_margin\"]\n",
    "        )\n",
    "\n",
    "        metrics[predictor] = {\n",
    "            \"Log Loss (home_win_pct)\": log_loss_home_win_pct,\n",
    "            \"MAE (home_score)\": mae_home_score,\n",
    "            \"MAE (away_score)\": mae_away_score,\n",
    "            \"MAE (home_margin)\": mae_home_margin,\n",
    "        }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e84a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, save=False, image_filename=None):\n",
    "    # Convert the metrics dictionary into a DataFrame and round values\n",
    "    df = pd.DataFrame(metrics).T.round(2)\n",
    "    df_unstacked = df.unstack().reset_index()\n",
    "    df_unstacked.columns = [\"Metric\", \"Predictor\", \"Value\"]\n",
    "\n",
    "    # Apply custom labels for the metrics\n",
    "    custom_labels = {\n",
    "        \"Home Score MAE\": \"Home Score\\nMAE\",\n",
    "        \"Away Score MAE\": \"Away Score\\nMAE\",\n",
    "        \"Home Margin MAE\": \"Home Margin\\nMAE\",\n",
    "        \"Home Win Prob Log Loss\": \"Home Win %\\nLog Loss\",\n",
    "    }\n",
    "    df_unstacked[\"Metric\"] = df_unstacked[\"Metric\"].map(custom_labels)\n",
    "\n",
    "    # Split DataFrame into MAE and Log Loss data\n",
    "    mae_df = df_unstacked[df_unstacked[\"Metric\"].str.contains(\"MAE\")]\n",
    "    log_loss_df = df_unstacked[df_unstacked[\"Metric\"].str.contains(\"Log Loss\")]\n",
    "\n",
    "    # Generate custom color palette\n",
    "    deep_palette = sns.color_palette(\"deep\")\n",
    "    custom_palette = {key: deep_palette[i] for i, key in enumerate(df_unstacked[\"Predictor\"].unique())}\n",
    "    custom_palette[\"MLP\"] = deep_palette[0]\n",
    "    custom_palette[\"Tree\"] = deep_palette[2]\n",
    "    custom_palette[\"Linear\"] = deep_palette[1]\n",
    "    custom_palette[\"Baseline\"] = deep_palette[7]\n",
    "\n",
    "    # Create subplots with recommended dimensions\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7), gridspec_kw={\"width_ratios\": [3, 1]})\n",
    "\n",
    "    # Plot MAE metrics\n",
    "    sns.barplot(data=mae_df, x=\"Metric\", y=\"Value\", hue=\"Predictor\", ax=ax1, palette=custom_palette)\n",
    "    ax1.set_ylabel(\"MAE (Points)\", fontsize=18, fontweight=\"bold\")\n",
    "    ax1.tick_params(axis=\"y\", labelsize=16)\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), fontsize=18, fontweight=\"bold\")\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel(\"\")\n",
    "    ax1.set_title(\"\")\n",
    "    ax1.xaxis.grid(False)\n",
    "\n",
    "    # Annotate values on MAE bars\n",
    "    for p in ax1.patches:\n",
    "        value = p.get_height()\n",
    "        if value > 0:\n",
    "            ax1.text(\n",
    "                p.get_x() + p.get_width() / 2,\n",
    "                value - 0.8,\n",
    "                f'{value:.2f}',\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=14,\n",
    "                weight='bold',\n",
    "                color='white'\n",
    "            )\n",
    "\n",
    "    # Plot Log Loss metrics\n",
    "    sns.barplot(data=log_loss_df, x=\"Metric\", y=\"Value\", hue=\"Predictor\", ax=ax2, palette=custom_palette)\n",
    "    ax2.set_ylabel(\"Log Loss\", rotation=270, labelpad=24, fontsize=18, fontweight=\"bold\")\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.tick_params(axis=\"y\", labelsize=16)\n",
    "    ax2.set_xticklabels(log_loss_df[\"Metric\"], fontsize=18, fontweight=\"bold\")\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xlabel(\"\")\n",
    "    ax2.set_title(\"\")\n",
    "    ax2.xaxis.grid(False)\n",
    "\n",
    "    # Annotate values on Log Loss bars\n",
    "    for p in ax2.patches:\n",
    "        value = p.get_height()\n",
    "        if value > 0:\n",
    "            ax2.text(\n",
    "                p.get_x() + p.get_width() / 2,\n",
    "                value - 0.04,\n",
    "                f'{value:.2f}',\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=14,\n",
    "                weight='bold',\n",
    "                color='white'\n",
    "            )\n",
    "\n",
    "    # Add a super title for the figure\n",
    "    fig.suptitle(\"Prediction Engine Performance\", fontsize=24, weight=\"bold\", y=1)\n",
    "\n",
    "    # Customize and add legend\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc=\"upper center\",\n",
    "        ncol=len(df_unstacked[\"Predictor\"].unique()),\n",
    "        title=\"Predictors\",\n",
    "        bbox_to_anchor=(0.5, 0.95),\n",
    "        fontsize=16,\n",
    "        title_fontproperties={'weight': 'bold', \"size\": 18}\n",
    "    )\n",
    "    ax1.get_legend().remove()\n",
    "    ax2.get_legend().remove()\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.90])\n",
    "\n",
    "    # Save the plot to a file if requested\n",
    "    if save and image_filename:\n",
    "        plt.savefig(f\"{image_filename}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab077e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Baseline\": {\n",
    "        \"Home Win Prob Log Loss\": 0.65,\n",
    "        \"Home Score MAE\": 9.65,\n",
    "        \"Away Score MAE\": 9.83,\n",
    "        \"Home Margin MAE\": 11.61,\n",
    "    },\n",
    "    \"Linear\": {\n",
    "        \"Home Win Prob Log Loss\": 0.62,\n",
    "        \"Home Score MAE\": 9.47,\n",
    "        \"Away Score MAE\": 9.46,\n",
    "        \"Home Margin MAE\": 11.25,\n",
    "    },\n",
    "    \"Tree\": {\n",
    "        \"Home Win Prob Log Loss\": 0.64,\n",
    "        \"Home Score MAE\": 9.62,\n",
    "        \"Away Score MAE\": 9.61,\n",
    "        \"Home Margin MAE\": 11.30,\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"Home Win Prob Log Loss\": 0.63,\n",
    "        \"Home Score MAE\": 9.41,\n",
    "        \"Away Score MAE\": 9.45,\n",
    "        \"Home Margin MAE\": 11.22,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics, save=True, image_filename=\"predictor_performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nba_ai_venv)",
   "language": "python",
   "name": "nba_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
